{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 2",
      "language": "python",
      "name": "python2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Hands-On-MNIST_Python_Neural_Network_Final.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/varunkr24/Neural-Network/blob/Python/Hands_On_MNIST_Python_Neural_Network_Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AfIVI6MQiMzE"
      },
      "source": [
        "### MNIST neural network from scratch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxZweULXiMzF"
      },
      "source": [
        "#### Fully Connected Layer (Linear Layer)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1FueIixfiMzG"
      },
      "source": [
        "import numpy as np \n",
        "\n",
        "class Linear():\n",
        "    def __init__(self, in_size, out_size):\n",
        "        self.W = np.random.randn(in_size, out_size) * 0.01\n",
        "        self.b = np.zeros((1, out_size))\n",
        "        self.params = [self.W, self.b]\n",
        "        self.gradW = None\n",
        "        self.gradB = None\n",
        "        self.gradInput = None        \n",
        "\n",
        "    def forward(self, X):\n",
        "        self.X = X\n",
        "        self.output = np.dot(X, self.W) + self.b\n",
        "        return self.output\n",
        "\n",
        "    def backward(self, nextgrad):\n",
        "        self.gradW = np.dot(self.X.T, nextgrad)\n",
        "        self.gradB = np.sum(nextgrad, axis=0)\n",
        "        self.gradInput = np.dot(nextgrad, self.W.T)\n",
        "        return self.gradInput, [self.gradW, self.gradB]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O33Noi4iiMzM"
      },
      "source": [
        "#### Rectified Linear Activation Layer (ReLU)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KOa9j3cfiMzN"
      },
      "source": [
        "class ReLU():\n",
        "    def __init__(self):\n",
        "        self.params = []\n",
        "        self.gradInput = None\n",
        "\n",
        "    def forward(self, X):\n",
        "        self.output = np.maximum(X, 0)\n",
        "        return self.output\n",
        "\n",
        "    def backward(self, nextgrad):\n",
        "        self.gradInput = nextgrad.copy()\n",
        "        self.gradInput[self.output <=0] = 0\n",
        "        return self.gradInput, []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XUl0dk6HiMzR"
      },
      "source": [
        "#### Defining the softmax function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUTsLik3iMzS"
      },
      "source": [
        "def softmax(x):\n",
        "    exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
        "    return exp_x / np.sum(exp_x, axis=1, keepdims=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zocFN7QQiMzV"
      },
      "source": [
        "#### Defining the Cross Entropy Loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wYY1bnEiMzW"
      },
      "source": [
        "class CrossEntropy:\n",
        "    def forward(self, X, y):\n",
        "        self.m = y.shape[0]\n",
        "        self.p = softmax(X)\n",
        "        cross_entropy = -np.log(self.p[range(self.m), y])\n",
        "        # loss = cross_entropy[0] / self.m         # please note this line was in the video however the correct line is the below one\n",
        "        loss = np.sum(cross_entropy) / self.m      # which involves taking a sum across the losses for all the examples in the batch\n",
        "        return loss\n",
        "    \n",
        "    def backward(self, X, y):\n",
        "        y_idx = y.argmax()        \n",
        "        grad = softmax(X)\n",
        "        grad[range(self.m), y] -= 1\n",
        "        grad /= self.m\n",
        "        return grad"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFAwwd53iMza"
      },
      "source": [
        "#### Loading the MNIST dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJLO_akoiMzb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "02d8bbc7-9dfe-4567-e5c6-2b490c2a0bf3"
      },
      "source": [
        "from keras.datasets import mnist\n",
        "from keras.utils import np_utils\n",
        "\n",
        "\n",
        "(train_features, train_targets), (test_features, test_targets) = mnist.load_data()\n",
        "\n",
        "\n",
        "train_features = train_features.reshape(60000, 784)\n",
        "print(train_features.shape)\n",
        "test_features = test_features.reshape(10000, 784)\n",
        "print(test_features.shape)\n",
        "\n",
        "\n",
        "# # normalize inputs from 0-255 to 0-1\n",
        "train_features = train_features / 255.0\n",
        "test_features = test_features / 255.0\n",
        "\n",
        "print(train_targets.shape)\n",
        "print(test_targets.shape)\n",
        "\n",
        "X_train = train_features\n",
        "y_train = train_targets\n",
        "\n",
        "X_val = test_features\n",
        "y_val = test_targets\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(60000, 784)\n",
            "(10000, 784)\n",
            "(60000,)\n",
            "(10000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YS6LnJwviMzg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116
        },
        "outputId": "a10896db-c2ac-4137-8470-108ae06b5eaf"
      },
      "source": [
        "# visualizing the first 10 images in the dataset and their labels\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(10, 1))\n",
        "for i in range(10):\n",
        "    plt.subplot(1, 10, i+1)\n",
        "    plt.imshow(X_train[i].reshape(28, 28), cmap=\"gray\")\n",
        "    plt.axis('off')\n",
        "plt.show()\n",
        "print('label for each of the above image: %s' % (y_train[0:10]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x72 with 10 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "label for each of the above image: [5 0 4 1 9 2 1 3 1 4]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJ587e81iMzk"
      },
      "source": [
        "#### Here, we define the container NN class that enables the forward prop and backward propagation of the entire network. Note, how this class enables us to add layers of different types and also correctly pass gradients using the chain rule."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X3u-gxUJiMzk"
      },
      "source": [
        "class NN():\n",
        "    def __init__(self, lossfunc=CrossEntropy()):\n",
        "        self.params = []\n",
        "        self.layers = []\n",
        "        self.loss_func = lossfunc\n",
        "        self.grads = []\n",
        "        \n",
        "    def add_layer(self, layer):\n",
        "        self.layers.append(layer)\n",
        "        self.params.append(layer.params)\n",
        "\n",
        "    def forward(self, X):\n",
        "        for layer in self.layers:\n",
        "            X = layer.forward(X)\n",
        "        return X\n",
        "    \n",
        "    def backward(self, nextgrad):\n",
        "        self.clear_grad_param()\n",
        "        for layer in reversed(self.layers):\n",
        "            nextgrad, grad = layer.backward(nextgrad)\n",
        "            self.grads.append(grad)\n",
        "        return self.grads\n",
        "    \n",
        "    def train_step(self, X, y):\n",
        "        out = self.forward(X)\n",
        "        loss = self.loss_func.forward(out,y)\n",
        "        nextgrad = self.loss_func.backward(out,y)\n",
        "        grads = self.backward(nextgrad)\n",
        "        return loss, grads\n",
        "    \n",
        "    def predict(self, X):\n",
        "        X = self.forward(X)\n",
        "        return np.argmax(X, axis=1)\n",
        "    \n",
        "    def predict_scores(self, X):\n",
        "        X = self.forward(X)\n",
        "        return X\n",
        "    \n",
        "    def clear_grad_param(self):\n",
        "        self.grads = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-NKsF22iMzn"
      },
      "source": [
        "#### Defining the update function (SGD with momentum)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LsNd7D7BiMzo"
      },
      "source": [
        "def update_params(velocity, params, grads, learning_rate=0.01, mu=0.9):\n",
        "    for v, p, g, in zip(velocity, params, reversed(grads)):\n",
        "        for i in range(len(g)):\n",
        "            v[i] = mu * v[i] + learning_rate * g[i]\n",
        "            p[i] -= v[i]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4qe-KMG_iMzs"
      },
      "source": [
        "#### Defining a function which gives us the minibatches (both the datapoint and the corresponding label)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFOyQ2ZGiMzs"
      },
      "source": [
        "# get minibatches\n",
        "def minibatch(X, y, minibatch_size):\n",
        "    n = X.shape[0]\n",
        "    minibatches = []\n",
        "    permutation = np.random.permutation(X.shape[0])\n",
        "    X = X[permutation]\n",
        "    y = y[permutation]\n",
        "    \n",
        "    for i in range(0, n , minibatch_size):\n",
        "        X_batch = X[i:i + minibatch_size, :]\n",
        "        y_batch = y[i:i + minibatch_size, ]\n",
        "        minibatches.append((X_batch, y_batch))\n",
        "        \n",
        "    return minibatches"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bdX0EnUgiMzw"
      },
      "source": [
        "#### The traning loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DM7XtCTjiMzx"
      },
      "source": [
        "def train(net, X_train, y_train, minibatch_size, epoch, learning_rate, mu=0.9, X_val=None, y_val=None):\n",
        "    val_loss_epoch = []\n",
        "    minibatches = minibatch(X_train, y_train, minibatch_size)\n",
        "    minibatches_val = minibatch(X_val, y_val, minibatch_size)\n",
        "\n",
        "    \n",
        "    for i in range(epoch):\n",
        "        loss_batch = []\n",
        "        val_loss_batch = []\n",
        "        velocity = []\n",
        "        for param_layer in net.params:\n",
        "            p = [np.zeros_like(param) for param in list(param_layer)]\n",
        "            velocity.append(p)\n",
        "            \n",
        "        # iterate over mini batches\n",
        "        for X_mini, y_mini in minibatches:\n",
        "            loss, grads = net.train_step(X_mini, y_mini)\n",
        "            loss_batch.append(loss)\n",
        "            update_params(velocity, net.params, grads, learning_rate=learning_rate, mu=mu)\n",
        "\n",
        "        for X_mini_val, y_mini_val in minibatches_val:\n",
        "            val_loss, _ = net.train_step(X_mini, y_mini)\n",
        "            val_loss_batch.append(val_loss)\n",
        "        \n",
        "        # accuracy of model at end of epoch after all mini batch updates\n",
        "        m_train = X_train.shape[0]\n",
        "        m_val = X_val.shape[0]\n",
        "        y_train_pred = np.array([], dtype=\"int64\")\n",
        "        y_val_pred = np.array([], dtype=\"int64\")\n",
        "        y_train1 = []\n",
        "        y_vall = []\n",
        "        for i in range(0, m_train, minibatch_size):\n",
        "            X_tr = X_train[i:i + minibatch_size, : ]\n",
        "            y_tr = y_train[i:i + minibatch_size,]\n",
        "            y_train1 = np.append(y_train1, y_tr)\n",
        "            y_train_pred = np.append(y_train_pred, net.predict(X_tr))\n",
        "\n",
        "        for i in range(0, m_val, minibatch_size):\n",
        "            X_va = X_val[i:i + minibatch_size, : ]\n",
        "            y_va = y_val[i:i + minibatch_size,]\n",
        "            y_vall = np.append(y_vall, y_va)\n",
        "            y_val_pred = np.append(y_val_pred, net.predict(X_va))\n",
        "            \n",
        "        train_acc = check_accuracy(y_train1, y_train_pred)\n",
        "        val_acc = check_accuracy(y_vall, y_val_pred)\n",
        "\n",
        "        mean_train_loss = sum(loss_batch) / float(len(loss_batch))\n",
        "        mean_val_loss = sum(val_loss_batch) / float(len(val_loss_batch))\n",
        "        \n",
        "        val_loss_epoch.append(mean_val_loss)\n",
        "        print(\"Loss = {0} | Training Accuracy = {1} | Val Loss = {2} | Val Accuracy = {3}\".format(mean_train_loss, train_acc, mean_val_loss, val_acc))\n",
        "    return net"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JauSFCZZiMz2"
      },
      "source": [
        "#### Checking the accuracy of the model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UlnmjqaviMz3"
      },
      "source": [
        "def check_accuracy(y_true, y_pred):\n",
        "    return np.mean(y_pred == y_true)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_JSqjs9iMz7"
      },
      "source": [
        "#### Invoking all that we have created until now"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ipPGnUmgiMz8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "a593b333-1015-4f04-8de8-66bcb08cbf70"
      },
      "source": [
        "from random import shuffle\n",
        "\n",
        "## input size\n",
        "input_dim = X_train.shape[1]\n",
        "\n",
        "## hyperparameters\n",
        "iterations = 10\n",
        "learning_rate = 0.1\n",
        "hidden_nodes = 32\n",
        "output_nodes = 10\n",
        "\n",
        "## define neural net\n",
        "nn = NN()\n",
        "nn.add_layer(Linear(input_dim, hidden_nodes))\n",
        "nn.add_layer(ReLU())\n",
        "nn.add_layer(Linear(hidden_nodes, output_nodes))\n",
        "\n",
        "nn = train(nn, X_train , y_train, minibatch_size=200, epoch=10, \\\n",
        "           learning_rate=learning_rate, X_val=X_val, y_val=y_val)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss = 0.493375107092 | Training Accuracy = 0.942233333333 | Val Loss = 0.220176431073 | Val Accuracy = 0.9431\n",
            "Loss = 0.180420163143 | Training Accuracy = 0.9589 | Val Loss = 0.215089449671 | Val Accuracy = 0.9558\n",
            "Loss = 0.135187090339 | Training Accuracy = 0.9683 | Val Loss = 0.199745372794 | Val Accuracy = 0.9641\n",
            "Loss = 0.112527660182 | Training Accuracy = 0.971083333333 | Val Loss = 0.198089330666 | Val Accuracy = 0.9655\n",
            "Loss = 0.0990982992547 | Training Accuracy = 0.972366666667 | Val Loss = 0.185731871607 | Val Accuracy = 0.9654\n",
            "Loss = 0.0890477338952 | Training Accuracy = 0.972933333333 | Val Loss = 0.177962630312 | Val Accuracy = 0.9638\n",
            "Loss = 0.0816574105042 | Training Accuracy = 0.972583333333 | Val Loss = 0.180185000214 | Val Accuracy = 0.9629\n",
            "Loss = 0.0752627184328 | Training Accuracy = 0.9736 | Val Loss = 0.187161768657 | Val Accuracy = 0.9627\n",
            "Loss = 0.0698048155026 | Training Accuracy = 0.975566666667 | Val Loss = 0.170875140377 | Val Accuracy = 0.9637\n",
            "Loss = 0.0643772522761 | Training Accuracy = 0.9773 | Val Loss = 0.149793065614 | Val Accuracy = 0.9639\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2pnlNifKiM0B"
      },
      "source": [
        "#### fprop a single image and showing its prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1Df46k3iM0C",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "a60b8210-a7f8-4a09-80ea-5568610a497b"
      },
      "source": [
        "plt.imshow(X_val[0].reshape(28,28), cmap='gray')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7ff89d8bfd10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7lyqu36iiM0G"
      },
      "source": [
        "# Predict Scores for each class\n",
        "prediction = nn.predict_scores(X_val[0])[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "LDTSzeTkiM0J",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "cc7ec49a-509b-4de9-9d91-c7b8039d9a47"
      },
      "source": [
        "print (\"Scores\")\n",
        "print (prediction)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Scores\n",
            "[ -0.03085549  -3.02966447   3.56212803   7.9520276  -13.83143547\n",
            "   0.83610854 -11.87031227  13.44597282   1.97990365   0.89517076]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTIiNdJliM0M",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c1ad281c-1d1e-4b75-977f-53a48b7fa69c"
      },
      "source": [
        "np.argmax(prediction)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9NyUYaViM0P",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5a3c037f-ca78-46b1-8cd2-ef6fc5da38d8"
      },
      "source": [
        "predict_class = nn.predict(X_val[0])[0]\n",
        "predict_class"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6_bSLc2iM0R",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a02ae4d2-114b-4837-da14-e9152a612726"
      },
      "source": [
        "# Original class\n",
        "y_val[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    }
  ]
}